{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personality Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data was collected through the PersonalityCafe forum, as it provides a large selection of people and their MBTI personality type, as well as what they have written.\n",
    "\n",
    "#### First Dataset:\n",
    "- There are 8675 observations(rows)\n",
    "- Each row has 1 individual’s personality type and their last 50 posts\n",
    "- The personality type shown is selected by the user although the forum has a link to the test for those members who do not know what personality type they belong to.\n",
    "\n",
    "#### Second Dataset:\n",
    "- Shows the frequency of each personality type in the population\n",
    "- Data source: \"MBTI Manual\" published by CPP\n",
    "\n",
    "#### Goal:\n",
    "Learn more about the correlations and differences between each personality type. Derive visuals and compare the personality types against each other.\n",
    "\n",
    "#### Motivation:\n",
    "I find psychology very interesting, I believe the more information people have, in this case about the personality type, the easier it will be for people to understand each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "\n",
    "# Always make it pretty.\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Dataset came in a csv so we can simply load it into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('mbti_1 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second dataset also came in a csv. Again, we just load it into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('TypePopulation.csv')\n",
    "print(population.info())\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Frequency column is a string, let's convert it into a float\n",
    "population['Frequency'] = population['Frequency'].apply(lambda x: x.replace('%',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population['Frequency'] = population['Frequency'].astype(float)\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning this up so we can merge it with the dataset above\n",
    "typecount = raw.groupby('type').agg({'type':'count'})\n",
    "typecount['Type']=typecount.index\n",
    "typecount.columns = ['Count','Type']\n",
    "typecount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsummary = pd.merge(population, typecount, on='Type')\n",
    "dfsummary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting frequency of personality types in our dataset against that found in the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(16,8))\n",
    "\n",
    "color = 'c'\n",
    "ax1.set_xlabel('Personality Type',size = 40)\n",
    "ax1.set_ylabel('Number of Observations', color=color,size=40)\n",
    "ax1.bar(dfsummary.Type,dfsummary.Count, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "plt.yticks(size=30)\n",
    "plt.xticks(rotation=45,size=30)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "color2 = 'orange'\n",
    "ax2.set_ylabel('Frequency in Population', color=color2,size=40)\n",
    "ax2.plot(dfsummary.Type, dfsummary.Frequency, color=color2)\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "plt.yticks(size=30)\n",
    "plt.xticks(rotation=45,size=30)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('samplebarvpop.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have an idea of the data let's get some information from our raw data\n",
    "- Words per comment\n",
    "- Links per comment\n",
    "- Questions asked per comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Words'] = raw['posts'].apply(lambda x: len(x.split())/50)\n",
    "raw['Links'] = raw['posts'].apply(lambda x: x.count('http')/50)\n",
    "raw['Questions'] = raw['posts'].apply(lambda x: x.count('?')/50)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ws = raw.groupby('type').agg({'Words':'mean'})\n",
    "Qs = raw.groupby('type').agg({'Questions':'mean'})\n",
    "Ls = raw.groupby('type').agg({'Links':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging our information to our summary DataFrame\n",
    "dfsummary = merge_to_df(dfsummary,Qs,'Questions')\n",
    "dfsummary = merge_to_df(dfsummary,Ls,'Links')\n",
    "dfsummary = merge_to_df(dfsummary,Ws,'Words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsummary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert our count column into a percentage\n",
    "dfsummary['SampleFr'] = dfsummary['Count']/len(raw)*100\n",
    "dfsummary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we've got our sample % let's compare it to the population %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(16,10))\n",
    "\n",
    "indices = range(len(dfsummary.Type))\n",
    "width = np.min(np.diff(indices))/3.\n",
    "ax1.set_xlabel('Personality Type',size = 40)\n",
    "ax1.set_ylabel('Representation %',size=40)\n",
    "ax1.bar(indices-width/2.,dfsummary.Frequency,width,color='darkviolet',label='Population')\n",
    "ax1.bar(indices+width/2.,dfsummary.SampleFr,width,color='darkcyan',label='Sample')\n",
    "ax1.set_xticklabels(dfsummary.Type.unique())\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "plt.yticks(size=30)\n",
    "plt.xticks(range(len(dfsummary.Type)), rotation=45,size=20)\n",
    "ax1.legend(prop={'size': 20})\n",
    "fig.tight_layout()\n",
    "fig.savefig('samplevpop.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data above, we can see that having “IN--” in the personality increases the chances of being active on a forum. Let's test this:\n",
    "\n",
    "- Null hypothesis: \"IN--\" personalities have a higher likelyhood of being in this online forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding another feature to our raw data\n",
    "raw['IN'] = raw['type'].apply(lambda x: present(x,'IN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsummary['IN'] = dfsummary['Type'].apply(lambda x: present(x,'IN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate the information\n",
    "IN = dfsummary.groupby('IN').agg({'Frequency':'sum','SampleFr':'sum','Count':'sum'})\n",
    "IN['Frequency'] = IN['Frequency'].astype(int)\n",
    "IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 8675 users, and 2978 of them are \"IN--\" we will test our hypothesis below, we will reject our hypothesis if we get a p-value greater than 0.05\n",
    "\n",
    "$$ \\text{# of \"IN--\"} \\approx Binomial(8675, 0.11) $$\n",
    "\n",
    "The central limit theorem tells us that a binomial with large $N$ is well approximated by a Normal distribution with the appropriate mean and varaince. Let's take a look at both plots belows.\n",
    "\n",
    "$$ Binomial(8675, 0.11) \\approx N(8675 \\times 0.11, \\sqrt{8675 \\times 0.11 \\times 0.89}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8675\n",
    "p = 0.11\n",
    "binomial = stats.binom(n=n, p=p)\n",
    "binomial_mean = p * n\n",
    "binomial_var = n * p * (1-p)\n",
    "normal_approx = stats.norm(binomial_mean, np.sqrt(binomial_var))\n",
    "x = np.linspace(0, n, num =8000)\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(16, 6))\n",
    "bar_sizes = [binomial.pmf(i) for i in range(n+1)]\n",
    "bars = axs[0].bar(range(n+1), bar_sizes, color=\"darkviolet\", align=\"center\")\n",
    "axs[0].plot(x, normal_approx.pdf(x), linewidth=3, alpha = 0.5)\n",
    "axs[0].set_xlim(800, 1100)\n",
    "\n",
    "bars = axs[1].bar(range(n+1), bar_sizes, color=\"grey\", align=\"center\")\n",
    "axs[1].plot(x, normal_approx.pdf(x), linewidth=3, alpha = 0.5)\n",
    "axs[1].set_xlim(800, 1100)\n",
    "\n",
    "axs[0].set_title('# of \"IN--\" observations given the Null Hypothesis')\n",
    "fig.savefig('distributions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with the Normal Distribution\n",
    "\n",
    "The p-value for this is:\n",
    "\n",
    "$$ P(\\geq \\text{ 2978 'IN--' observations} \\mid \\text{Null Hypothesis} ) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = 1 - normal_approx.cdf(2978)\n",
    "print(\"p-value for the experiment: {:2.6f}\".format(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(16, 3))\n",
    "\n",
    "ax.plot(x, normal_approx.pdf(x), linewidth=3,color='red',alpha=0.5)\n",
    "ax.set_xlim(850, 3200)\n",
    "ax.fill_between(x, normal_approx.pdf(x), where=(x >= 2978), color=\"b\",linewidth=3)\n",
    "ax.arrow(2978,0.008,0.,-0.006,head_width=20, head_length=0.002, fc='black', ec='black')\n",
    "ax.text(2900,0.009,'p-value', color='black', fontsize=18)\n",
    "ax.set_title(\"p-value Reigon\")\n",
    "fig.savefig('pvalue.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data, we accept the Null Hypothesis\n",
    "\n",
    "Let's take a look at all \"IN--\" personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsummary[dfsummary.IN == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we confidently say that INTPs ask more questions than the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(16, 6))\n",
    "INTP = raw['Questions'][(raw.IN == 1) & (raw.type == 'INTP')]\n",
    "INTJ = raw['Questions'][(raw.IN == 1) & (raw.type == 'INTJ')]\n",
    "INFJ = raw['Questions'][(raw.IN == 1) & (raw.type == 'INFJ')]\n",
    "INFP = raw['Questions'][(raw.IN == 1) & (raw.type == 'INFP')]\n",
    "\n",
    "ax.scatter(INTP, np.repeat(0, len(INTP)) + np.random.normal(0, 0.1, len(INTP)), s=45)\n",
    "ax.scatter(INTJ, np.repeat(1, len(INTJ)) + np.random.normal(1, 0.1, len(INTJ)), s=45)\n",
    "ax.scatter(INFJ, np.repeat(2, len(INFJ)) + np.random.normal(2, 0.1, len(INFJ)), s=45)\n",
    "ax.scatter(INFP, np.repeat(3, len(INFP)) + np.random.normal(3, 0.1, len(INFP)), s=45)\n",
    "ax.set_yticks([0,2,4,6])\n",
    "ax.set_yticklabels([\"INTP\",\"INTJ\",\"INFJ\",\"INFP\"])\n",
    "ax.set_xlabel('Ratio of # of Questions to Posts',size = 30)\n",
    "ax.set_ylabel('Personality Type',size=30)\n",
    "plt.yticks(size=20)\n",
    "plt.xticks(size=20)\n",
    "fig.savefig('ratios.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(INFJ))\n",
    "print(len(INTJ))\n",
    "print(len(INTP))\n",
    "print(len(INFP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a Skeptical Stance, and Clearly State This Hypothesis.\n",
    "\n",
    "> there is no difference in the average amount of questions asked between INTP and INTJ.\n",
    "\n",
    "> there is no difference in the average amount of questions asked between INTP and INFJ.\n",
    "\n",
    "> there is no difference in the average amount of questions asked between INTP and INFP.\n",
    "\n",
    "Our question concerns population averages (is INTP's question average different than INTJ, INFJ and INFP).  Our measurements are sample averages, which, from the central limit theorem, we know are approximately normally distributed given the population average\n",
    "\n",
    "$$ \\text{Sample average of INTP's questions} \\sim Normal \\left( \\mu_T, \\sqrt{\\frac{\\sigma^2_T}{1304}} \\right) $$\n",
    "$$ \\text{Sample average of INTJ's questions} \\sim Normal \\left( \\mu_J, \\sqrt{\\frac{\\sigma^2_J}{1091}} \\right) $$\n",
    "$$ \\text{Sample average of INFJ's questions} \\sim Normal \\left( \\mu_F, \\sqrt{\\frac{\\sigma^2_F}{1470}} \\right) $$\n",
    "$$ \\text{Sample average of INFP's questions} \\sim Normal \\left( \\mu_P, \\sqrt{\\frac{\\sigma^2_P}{1832}} \\right) $$\n",
    "\n",
    "If we are willing to assume that the Questions posted by INTP are independent from the other personalities, then we can compress the importnat information into one normal distribution\n",
    "\n",
    "$$ \\text{Difference in sample averages} \\sim Normal \\left( \\mu_T - \\mu_J, \\sqrt{\\frac{\\sigma^2_T}{1304} + \\frac{\\sigma^2_J}{1091}} \\right) $$\n",
    "$$ \\text{Difference in sample averages} \\sim Normal \\left( \\mu_T - \\mu_F, \\sqrt{\\frac{\\sigma^2_T}{1304} + \\frac{\\sigma^2_F}{1470}} \\right) $$\n",
    "$$ \\text{Difference in sample averages} \\sim Normal \\left( \\mu_T - \\mu_P, \\sqrt{\\frac{\\sigma^2_T}{1304} + \\frac{\\sigma^2_P}{1832}} \\right) $$\n",
    "\n",
    "Under the assumption of the null hypothesis\n",
    "\n",
    "$$ \\text{Difference in sample averages} \\sim Normal \\left( 0, \\sqrt{\\frac{\\sigma^2_T}{1304} + \\frac{\\sigma^2_J}{1091}} \\right) $$\n",
    "$$ \\text{Difference in sample averages} \\sim Normal \\left( 0, \\sqrt{\\frac{\\sigma^2_T}{1304} + \\frac{\\sigma^2_F}{1470}} \\right) $$\n",
    "$$ \\text{Difference in sample averages} \\sim Normal \\left( 0, \\sqrt{\\frac{\\sigma^2_T}{1304} + \\frac{\\sigma^2_P}{1832}} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where we have to independently estiamte the variance of a normal distribution from the same samples we are testing, this estimation of the variance contributes to uncertenty in our test.  This means that the Normal distribution is then **too precise** to use as a conservative estimate of the p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welch's t-test\n",
    "\n",
    "To recify the problem, we first convert to a sample statistic whose variance is expected to be $1$\n",
    "\n",
    "$$ \\frac{\\text{Difference in sample averages}}{\\sqrt{\\frac{\\sigma^2_T}{1304} + \\frac{\\sigma^2_J}{1091}}} $$\n",
    "$$ \\frac{\\text{Difference in sample averages}}{\\sqrt{\\frac{\\sigma^2_T}{1304} + \\frac{\\sigma^2_F}{1470}}} $$\n",
    "$$ \\frac{\\text{Difference in sample averages}}{\\sqrt{\\frac{\\sigma^2_T}{1304} + \\frac{\\sigma^2_P}{1832}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we still have a similar issue to the two sample test of population proportions, we do not know the population varainces in the denominator of the formula, so our only recourse is to substitute in the sample variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistic1 = welch_test_statistic(INTP, INTJ)\n",
    "print(\"Welch Test Statistic(v. INTJ): {:2.2f}\".format(test_statistic1))\n",
    "test_statistic2 = welch_test_statistic(INTP, INFJ)\n",
    "print(\"Welch Test Statistic(v. INFJ): {:2.2f}\".format(test_statistic2))\n",
    "test_statistic3 = welch_test_statistic(INTP, INFP)\n",
    "print(\"Welch Test Statistic(v. INFP): {:2.2f}\".format(test_statistic3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortuantely, this changes the distribution of the test statistic.  Instead of using a normal distribution, we must now use a **Student's t-distribution**, which accounts for the extra uncertenty in estimating the two new parameters.\n",
    "\n",
    "The t-distribution always has mean $0$ and varaince $1$, and has one parameter, the **degrees of freedom**.  Smaller degrees of freedom have heavyer tails, with the distribution beoming more normal as the degrees of freedom gets larger.\n",
    "\n",
    "The resulting application to our situation results in [Welch's t-test](https://en.wikipedia.org/wiki/Welch's_t-test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "welchdf1 = welch_satterhwaithe_df(INTP, INTJ)\n",
    "print(\"Degrees of Freedom for Welch's Test: {:2.2f}\".format(welchdf1))\n",
    "welchdf2 = welch_satterhwaithe_df(INTP, INFJ)\n",
    "print(\"Degrees of Freedom for Welch's Test: {:2.2f}\".format(welchdf2))\n",
    "welchdf3 = welch_satterhwaithe_df(INTP, INFP)\n",
    "print(\"Degrees of Freedom for Welch's Test: {:2.2f}\".format(welchdf3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, num=250)\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(16, 9))\n",
    "students1 = stats.t(welchdf1)\n",
    "students2 = stats.t(welchdf2)\n",
    "students3 = stats.t(welchdf3)\n",
    "ax[0].plot(x, students1.pdf(x), linewidth=2, \n",
    "        label=\"Degree of Freedom: {:2.2f}\".format(welchdf1))\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Distribution of Welsh's Test Statistic Under the Null Hypothesis\")\n",
    "ax[1].plot(x, students2.pdf(x), linewidth=2, \n",
    "        label=\"Degree of Freedom: {:2.2f}\".format(welchdf2))\n",
    "ax[1].legend()\n",
    "# ax[1].set_title(\"Distribution of Welsh's Test Statistic Under the Null Hypothesis\")\n",
    "ax[2].plot(x, students3.pdf(x), linewidth=2, \n",
    "        label=\"Degree of Freedom: {:2.2f}\".format(welchdf3))\n",
    "ax[2].legend()\n",
    "fig.savefig('welchttest.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, num=250)\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(16, 9))\n",
    "ax[0].plot(x, students1.pdf(x), linewidth=2, label=\"Degree of Freedom: {:2.2f}\".format(welchdf1))\n",
    "ax[0].fill_between(x, students1.pdf(x), where=(x >= -test_statistic1), color=\"red\", alpha=0.25)\n",
    "ax[0].fill_between(x, students1.pdf(x), where=(x <= test_statistic1), color=\"b\", alpha=0.25)\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"p-value Region\")\n",
    "\n",
    "ax[1].plot(x, students1.pdf(x), linewidth=2, label=\"Degree of Freedom: {:2.2f}\".format(welchdf2))\n",
    "ax[1].fill_between(x, students2.pdf(x), where=(x >= -test_statistic2), color=\"red\", alpha=0.25)\n",
    "ax[1].fill_between(x, students2.pdf(x), where=(x <= test_statistic2), color=\"b\", alpha=0.25)\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"p-value Region\")\n",
    "\n",
    "ax[2].plot(x, students1.pdf(x), linewidth=2, label=\"Degree of Freedom: {:2.2f}\".format(welchdf3))\n",
    "ax[2].fill_between(x, students3.pdf(x), where=(x >= -test_statistic3), color=\"red\", alpha=0.25)\n",
    "ax[2].fill_between(x, students3.pdf(x), where=(x <= test_statistic3), color=\"b\", alpha=0.25)\n",
    "ax[2].legend()\n",
    "ax[2].set_title(\"p-value Region\")\n",
    "fig.savefig('pvalueregion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result we can see that our datasets are not normally distributed, this is a good lesson for next time. Check the distribution before moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This means we must use: *Mann-Whitney Signed Rank Test*\n",
    "Let us rephrase our null hypothesis to what we started with:\n",
    "\n",
    "> $H_0$: INTPs ratio of questions to posts are equally likely to INTJs. i.e\n",
    "  \n",
    "  $$P(\\text{INTPs questions/post} > \\text{INTJs questions/post}) = 0.5$$\n",
    "\n",
    "> $H_0$: INTPs ratio of questions to posts are equally likely to INFJs. i.e\n",
    "  \n",
    "  $$P(\\text{INTPs questions/post} > \\text{INFJs questions/post}) = 0.5$$\n",
    "\n",
    "> $H_0$: INTPs ratio of questions to posts are equally likely to INFPs. i.e  \n",
    "  \n",
    "  $$P(\\text{INTPs questions/post} > \\text{INFPs questions/post}) = 0.5$$\n",
    "\n",
    "We will set a rejection threshold of **0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = stats.mannwhitneyu(INTP, INTJ, alternative=\"greater\")\n",
    "print(\"p-value for INTP > INTJ: {:2.10f}\".format(res1.pvalue))\n",
    "res2 = stats.mannwhitneyu(INTP, INFJ, alternative=\"greater\")\n",
    "print(\"p-value for INTP > INFJ: {:2.10f}\".format(res2.pvalue))\n",
    "res3 = stats.mannwhitneyu(INTP, INFP, alternative=\"greater\")\n",
    "print(\"p-value for INTP > INFP: {:2.10f}\".format(res3.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our results:\n",
    "\n",
    "> we fail to reject the first Null Hypothesis\n",
    "\n",
    "> we reject the second Null Hypothesis\n",
    "\n",
    "> we reject the third Null Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's go back to the data and see what we can derive\n",
    "- Create a dictionary with all the observations of each Personality Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={}\n",
    "for ptype in raw['type'].unique():\n",
    "        d[ptype]=raw.loc[raw['type'] == ptype,'posts':'posts']\n",
    "        d[ptype].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the word frequency by personality type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = {}\n",
    "for k,v in d.items():\n",
    "    d2[k] = wordFrequency(v['posts'])\n",
    "d2['INTP'].most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After creating the dictionaries shown above, it made sense to create some word clouds.\n",
    "- Getting the 30 most common words for all personality types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = wordFrequency(raw['posts'])\n",
    "common_words.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of the 30 most common words\n",
    "remove = []\n",
    "for item in common_words.most_common(30):\n",
    "    remove.append(' '+item[0]+' ')\n",
    "remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the 30 most common words in order to create wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['posts'] = df2['posts'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a word cloud for each personality type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "fig, ax = plt.subplots(len(raw['type'].unique()), sharex=True, \n",
    "                       figsize=(15,10*len(df2['type'].unique())))\n",
    "\n",
    "x = 0 #will serve as our plot index\n",
    "for i in df2['type'].unique():\n",
    "    df = df2[df2['type'] == i]\n",
    "    wordcloud = WordCloud(background_color=\"white\", max_words=100, colormap=\"tab10\",\n",
    "                          mask=transformed_head_mask).generate(df['posts'].to_string())\n",
    "    ax[x].imshow(wordcloud, interpolation='bilinear')\n",
    "    ax[x].set_title(i)\n",
    "    ax[x].axis(\"off\")\n",
    "    wordcloud.to_file(\"{}.png\".format(i))\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To create the mask we import the image as an array\n",
    "- you need to import Image from PIL\n",
    "- as seen below, we get an array that has 0s, we need to change this to 255 in order to use it with our word cloud\n",
    "- need to check the shape so we can make a mask with the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_mask = np.array(Image.open(\"head2.png\"))\n",
    "print(head_mask.shape)\n",
    "print(head_mask[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the function \"transform_mask\" to populate a new array\n",
    "- once complete, verify the values have changed and the shape matches the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_head_mask = np.ndarray((head_mask.shape[0],head_mask.shape[1], \n",
    "                                    head_mask.shape[2]),np.int32)\n",
    "transformed_head_mask\n",
    "for i in range(len(head_mask)):\n",
    "    transformed_head_mask[i] = list(map(transform_mask, head_mask[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_head_mask.shape)\n",
    "print(transformed_head_mask[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we go back to our dataset, verify that we have numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsummary.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsummary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(dfsummary,figsize=(16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We don't seem to have any obvious correlations between any of the independant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "- Here are all the functions used throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordFrequency(series):\n",
    "    \"\"\"\n",
    "    Takes in the ['posts'] column and creates a dictionary of the words \n",
    "    found where the values are the frequncy of the word\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    series: a pandas.series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dictionary\n",
    "    \"\"\"\n",
    "    count = Counter()\n",
    "    for posts in series:\n",
    "        pt = posts.split('|||')\n",
    "        for sentance in pt:\n",
    "            words = sentance.split(' ')\n",
    "            for w in words:\n",
    "                count[w] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mask(matrix):\n",
    "    \"\"\"\n",
    "    Takes a 2D Matrix in and changes the 0 values to 255\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Matrix: 2D matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "    \"\"\"\n",
    "    l =[]\n",
    "    for n in matrix:\n",
    "        if n == 0:\n",
    "            l.append(255)\n",
    "        else:\n",
    "            l.append(n)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_to_df(df,series,newcol):\n",
    "    \"\"\"\n",
    "    Prepares a series to be merged with my summary df.\n",
    "    Checks to see if the column exists, if it doesn't it returns\n",
    "    the merged dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.dataframe\n",
    "    series: a pandas.series\n",
    "    newcol: String\n",
    "    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    series\n",
    "    \"\"\"\n",
    "    series['Type']=series.index\n",
    "    series.coulmns = [newcol,'Type']\n",
    "    if newcol in df.columns:\n",
    "        return \"Coloumn already in dataframe\"\n",
    "    else:\n",
    "        return pd.merge(df, series, on='Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    \"\"\"\n",
    "    Removes all common text from the line and returns a cleaned version of the line\n",
    "    String.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series: a pandas.series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    String\n",
    "    \"\"\"\n",
    "    for char in remove:\n",
    "        string = string.replace(char,' ')\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present(string,chars):\n",
    "    \"\"\"\n",
    "    Checks if char is in string.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    string: string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int: 1 for yes\n",
    "         0 for no\n",
    "    \"\"\"\n",
    "    if chars in string:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welch_test_statistic(sample_1, sample_2):\n",
    "    \"\"\"\n",
    "    Takes two samples as a list or pandas.series and returns the Welch Test Statistic\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_1: list or pandas.series\n",
    "    sample_2: list or pandas.series\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float: welch test statistic \n",
    "    \"\"\"\n",
    "    numerator = np.mean(sample_1) - np.mean(sample_2)\n",
    "    denominator_sq = (np.var(sample_1) / len(sample_1)) + (np.var(sample_2) / len(sample_2))\n",
    "    return numerator / np.sqrt(denominator_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welch_satterhwaithe_df(sample_1, sample_2):\n",
    "    ss1 = len(sample_1)\n",
    "    ss2 = len(sample_2)\n",
    "    df = (\n",
    "        ((np.var(sample_1)/ss1 + np.var(sample_2)/ss2)**(2.0)) / \n",
    "        ((np.var(sample_1)/ss1)**(2.0)/(ss1 - 1) + (np.var(sample_2)/ss2)**(2.0)/(ss2 - 1))\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a wordcloud for the Q&A portion of the presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = ['Q&A','Q&A','Q&A','Q&A','Q&A','Q&A','Q&A','WHO?','WHO?', 'WHO?', 'WHO?',\n",
    "      'WHAT?','WHAT?','WHAT? WHERE?','WHERE?','WHERE? WHEN?','WHEN?','WHEN? WHY?',\n",
    "      'WHY?','WHY? HOW?','HOW?','HOW?','Q&A','Q&A','Q&A','Q&A','Q&A','WHO?', 'WHO?', \n",
    "      'WHO? WHAT?','WHAT?','WHAT? WHERE?','WHERE?','WHERE?','WHEN?','WHEN?','WHEN? WHY?',\n",
    "      'WHY?','WHY?','HOW?','HOW?','HOW?']\n",
    "wcd=Counter(QA)\n",
    "fig, ax = plt.subplots(1, figsize=(16, 10))\n",
    "wc = WordCloud(background_color=\"white\",colormap=\"tab10\").generate_from_frequencies(wcd)\n",
    "ax.imshow(wc, interpolation='bilinear')\n",
    "ax.set_title('Q&A')\n",
    "ax.axis(\"off\")\n",
    "wc.to_file(\"QA.png\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.1",
    "jupytext_version": "1.1.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
